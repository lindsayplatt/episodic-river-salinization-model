
#' @title Extract importance data from a random forest model
#' @description This function pulls the `importance` data from a `randomForest`
#' model object and reformats as a `tibble` for both importance and importance
#' standard deviation (so that we can create +/- lines around importance).
#' 
#' @param rf_model a model object of a random forest that was already run; likely
#' returned from `apply_randomforest()`
#' 
#' @returns a tibble with a row per site category & site attribute combination with
#' the columns `attribute`, `site_category`, `importance`, `importance_sd`, and
#' `attribute_grp`.
#' 
calculate_attr_importance <- function(rf_model) {
  
  # Prepare importance data
  rf_importance <- rf_model$importance %>% 
    as_tibble(rownames = 'attribute') %>% 
    dplyr::select(-MeanDecreaseGini, -MeanDecreaseAccuracy) %>% 
    pivot_longer(matches('high|low|none'), 
                 names_to = 'site_category',
                 values_to = 'importance') 
  
  # Prepare importance SD data
  rf_importance_sd <- rf_model$importanceSD %>% 
    as_tibble(rownames = 'attribute') %>% 
    dplyr::select(-MeanDecreaseAccuracy) %>% 
    pivot_longer(matches('high|low|none'), 
                 names_to = 'site_category',
                 values_to = 'importance_sd')
  
  # Prepare mean importance data
  rf_means_importance <- rf_model$importance %>% 
    as_tibble(rownames = 'attribute') %>% 
    mutate(site_category = 'Overall mean')  %>% 
    dplyr::select(attribute, site_category, importance = MeanDecreaseAccuracy) %>% 
    distinct()
  
  # Prepare mean importance SD data
  rf_means_importance_sd <- rf_model$importanceSD %>% 
    as_tibble(rownames = 'attribute') %>% 
    mutate(site_category = 'Overall mean') %>% 
    dplyr::select(attribute, site_category, importance_sd = MeanDecreaseAccuracy) %>% 
    distinct()
  
  # Prepare overall importance table
  bind_rows(rf_importance, rf_means_importance) %>% 
    left_join(bind_rows(rf_importance_sd, rf_means_importance_sd), 
              by = c('attribute', 'site_category')) %>% 
    dplyr::select(attribute, site_category, everything()) %>% 
    mutate(attribute_grp = case_when(
      attribute %in% c('annualPrecip', 'annualSnow', 'winterAirTemp',
                       'annualSnow_upstream') ~ 'meteo',
      attribute %in% c('roadSaltPerSqKm', 'roadSaltCumulativePerSqKm') ~ 'salt',
      attribute %in% c('baseFlowInd', 'gwRecharge', 'depthToWT', 
                       'gwRecharge_upstream', 'depthToWT_upstream', 
                       'subsurfaceContact', 'transmissivity') ~ 'gw',
      attribute %in% c('pctAgriculture', 'pctDeveloped', 'pctForested', 
                       'pctAgriculture_upstream', 'pctDeveloped_upstream', 'pctForested_upstream', 
                       'pctOpenWater', 'pctWetland') ~ 'landcover',
      attribute %in% c('basinSlope', 'medianFlow', 
                       'basinSlope_upstream') ~ 'basin',
      .default = NA_character_
    ))
  
}

#' @title Create an importance plot
#' @description This function generates a faceted plot of ranked attribute 
#' importance, where there is a different facet per site category (including
#' the overall attribute mean importance among all categories). 
#' 
#' @param rf_model_importance a tibble with attribute importance from a random
#' forest model, generated by `calculate_attr_importance()` with a row per site 
#' category & site attribute combination with the columns `attribute`, `site_category`, 
#' `importance`, `importance_sd`, and `attribute_grp`.
#' 
#' @returns a ggplot object
#'
visualize_attr_importance1 <- function(rf_model_importance) {
  
  data_to_plot <- rf_model_importance %>% filter(site_category == 'Overall mean') %>% 
    # Order the attributes based on importance values *within* each site category
    # Thanks to https://stackoverflow.com/questions/72147790/ggplot-facet-different-y-axis-order-based-on-value!
    mutate(attribute = tidytext::reorder_within(attribute, importance, within = site_category)) 
  
  # Var importance per site category, ordered by attribute importance
  ggplot(data_to_plot, aes(x = importance, y = attribute,
                           color = attribute_grp)) +
    geom_point(size = 3) +
    geom_segment(aes(x = importance - importance_sd,
                     xend = importance + importance_sd,
                     yend = attribute), linewidth=1) +
    # facet_wrap(vars(site_category), scales = 'free', nrow = 1) +
    tidytext::scale_y_reordered() +
    scico::scale_color_scico_d(name = 'Attribute group', palette = 'lajolla',
                               begin = 0.25, end = 0.75) +
    theme_bw() +
    theme(axis.title.y = element_blank(),
          axis.title.x = element_text(size=14),
          axis.text.y = element_text(size=14),
          axis.text.x = element_text(size=12),
          legend.text = element_text(size=12),
          legend.title = element_text(face='bold'),
          panel.grid.major.y = element_blank(),
          strip.background = element_blank(),
          strip.text = element_text(face = 'bold', size = 12)) +
    xlab('Gini index of importance')
  
  # '#0b5394' - color for episodic in slidedeck.
}

# TODO: show partial dependence of two features? 
# https://christophm.github.io/interpretable-ml-book/pdp.html#examples
#' @title Calculate partial dependence for each attribute
#' @description Given the output of a random forest model, this function uses
#' the `pdp::partial()` function to calculate the partial dependence of each
#' attribute and site category in the model.
#' 
#' @param rf_model a model object of a random forest that was already run; likely
#' returned from `apply_randomforest()`
#' @param site_attr_data a tibble with the columns `site_category_fact` and any
#' number of columns that give static attributes (not prefixed with `attr_`)
#' @param focus_class a character string corresponding to one of the classes in
#' the model and data that will be used as the focus of the partial dependence line.
#' 
#' @returns a data.frame of partial dependence with the columns `attribute`, 
#' `site_category`, `attr_val`, and `attr_partdep`.
#' 
calculate_partial_dependence <- function(rf_model, site_attr_data, focus_class) {
  
  numeric_attrs <- rf_model$importance %>% rownames()

  var_partials <- map(numeric_attrs, ~{
    pdp::partial(
      rf_model,
      pred.var = .x, 
      prob = TRUE, 
      which.class = focus_class,
      train = site_attr_data
    ) %>% setNames(c('attr_val', 'attr_partdep')) %>% 
      mutate(attribute = .x, 
             site_category = focus_class, .before='attr_val')
  }) %>% 
    bind_rows()
}

#' @title Create a plot of partial dependence lines
#' @description This function creates a plot with facets for each attribute and 
#' shows partial dependence lines for each site category. It also adds a rug 
#' (little vertical lines at the bottom) to show the actual attribute values that
#' went into the model.
#' 
#' @param pdp_data a data.frame of partial dependence returned from `calculate_partial_dependence()` 
#' with the columns `attribute`, `site_category`, `attr_val`, and `attr_partdep`
#' @param real_attribute_values a tibble with the columns `site_category_fact` and
#' any number of columns that give static attributes (not prefixed with `attr_`)
#' 
#' @returns a ggplot object
#' 
visualize_partial_dependence <- function(pdp_data, real_attribute_values) {
  
  # Use the actual values of the attributes to add a rug on the bottom so 
  # we can tell which patterns of dependence for given attributes are 
  # maybe just artifacts of a lack of input data.
  real_attribute_values_to_plot <- real_attribute_values %>% 
    # Reshape the data
    pivot_longer(-site_category_fact, names_to = 'attribute', values_to = 'attr_val') %>% 
    filter(attribute %in% unique(pdp_data$attribute)) %>% 
    # Log scale appropriate attributes for visual purposes
    log_transform_to_select_attributes() %>%
    rename(site_category = site_category_fact) 
  
  pdp_data %>% 
    # Log scale appropriate attributes for visual purposes
    log_transform_to_select_attributes() %>%
    ggplot(aes(x = attr_val)) +
    facet_wrap(vars(attribute), scales = 'free_x') +
    scico::scale_color_scico_d(begin = 0, end = 0.75) +
    geom_line(aes(y = attr_partdep), color = 'black', linewidth = 1.5) +
    geom_rug(data=real_attribute_values_to_plot, sides='b') +
    theme_bw() +
    theme(text = element_text(size=16), 
          strip.background = element_blank(),
          strip.text = element_text(size = 18, face = 'bold')) +
    ylab('Probability') + xlab('')
}

# TODO: SHAP eval???
# library(kernelshap)
# library(shapviz)
# library(randomForest)
# 
# fit <- tar_read(p5_rf_model_optimal)
# dat <- tar_read(p5_site_attr_rf)
# 
# # Step 1: Calculate Kernel SHAP values
# # bg_X is usually a small (50-200 rows) subset of the data
# set.seed(19)
# s <- kernelshap(fit, dat[-1], bg_X = sample_n(dat, 50)) # Just 50 rows took like 30 min
# s <- kernelshap(fit, dat[-1], bg_X = dat)
# 
# # Step 2: Turn them into a shapviz object
# sv <- shapviz(s)
# 
# # Step 3: Gain insights...
# sv_importance(sv, kind = "bee")
# sv_dependence(sv, v = "roadSalt", color_var = "auto")
